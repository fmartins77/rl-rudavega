{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x0HZBZX5lSnu"},"outputs":[],"source":["username = 'fmartins77'\n","git_token = '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'\n","repository = 'rl-rudavega'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RTOql9tCOlxh"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"5jhb_ahL1jiy"},"source":["Another change made only for testing"]},{"cell_type":"markdown","metadata":{"id":"sks4uVLfREoB"},"source":["# A/B/n Testing"]},{"cell_type":"markdown","metadata":{"id":"VaI1SmZafGSm"},"source":["We first create a function factory that will create a random number generator that generates normal variates with a given mean and standard deviation:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxbUU6H-RvJx"},"outputs":[],"source":["def normal_generator(mean, stdev, rng):\n","    def generator():\n","        return rng.normal(mean, stdev)\n","    return generator"]},{"cell_type":"markdown","metadata":{"id":"-dNM2uapU8cR"},"source":["Let's now implement A/B/n Testing.\n","\n","We first simulate the game choosing a random action for a certain number of steps."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126,"status":"ok","timestamp":1683757024117,"user":{"displayName":"Luiz Felipe Martins","userId":"02488179495456249327"},"user_tz":240},"id":"aglKcajRUBSe","outputId":"fa02e891-1ef3-474a-8759-8401d4bd7737"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training results\n","Action 0: Count: 198 Value: 1.0794119031506175\n","Action 1: Count: 204 Value: 2.271695036128357\n","Action 2: Count: 204 Value: 2.1292896561988575\n","Action 3: Count: 201 Value: 1.154292804913939\n","Action 4: Count: 193 Value: 2.1130371998782436\n","Best action: 1 Value: 2.271695036128357\n"]}],"source":["# Restart random number generator\n","rng = np.random.default_rng(seed=42)  \n","\n","# Define array of actions\n","nactions = 5\n","means = [1.1, 2.3, 2.2, 1.2, 2.1]\n","stdevs = [1, 1, 1, 1, 1]\n","reward_generators = [normal_generator(mean, stdev, rng) for mean, stdev in zip(means, stdevs)]\n","\n","# Initialize simulation\n","nsteps = 1000\n","action_values = np.zeros(nactions, dtype=np.float64)\n","action_counts = np.zeros(nactions, dtype=np.int64)\n","\n","# Run simulation\n","for _ in range(nsteps):\n","    action = rng.integers(nactions)\n","    reward = reward_generators[action]()\n","    action_counts[action] += 1\n","    action_values[action] += (reward - action_values[action]) / action_counts[action]\n","print('Training results')\n","for i in range(nactions):\n","  print(f'Action {i}: Count: {action_counts[i]} Value: {action_values[i]}')\n","best_action = np.argmax(action_values)\n","best_value = action_values[best_action]\n","print(f'Best action: {best_action} Value: {best_value}')"]},{"cell_type":"markdown","metadata":{"id":"CPWS6eRIf4Ky"},"source":["Things to experiment with:\n","\n","- Run the code above with different values of the seed. Is there variation on the best action selected?\n","\n","- Run the code with different values of the means and standard deviation.\n","\n","- Is there a minimum number of steps that reliably selects the best action for any values of the parameters?\n","\n","(It is possible to give a precise answer to this question, depending on the values of the standard deviations. A way to get a feeling for that experimentally would be to compare only two actions with close means and different standard deviations)"]},{"cell_type":"markdown","metadata":{"id":"0dMaJ6dwt3Q7"},"source":["# $\\epsilon$ Greedy Actions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1683757303658,"user":{"displayName":"Luiz Felipe Martins","userId":"02488179495456249327"},"user_tz":240},"id":"4dgeYTmbbC_k","outputId":"f99e3f74-a6d5-45aa-f062-4a1190f61de0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training results\n","Action 0: Count: 5 Value: 0.33055188588313\n","Action 1: Count: 9989 Value: 2.2861703712256958\n","Action 2: Count: 5 Value: 2.112255655820844\n","Action 3: Count: 1 Value: 1.2547221814541167\n","Action 4: Count: 0 Value: 0.0\n","Best action: 1 Value: 2.2861703712256958\n"]}],"source":["# Restart random number generator\n","rng = np.random.default_rng(seed=2048)  \n","\n","# Define array of actions\n","nactions = 5\n","means = [1.1, 2.3, 2.2, 1.2, 2.1]\n","stdevs = [1, 1, 1, 1, 1]\n","reward_generators = [normal_generator(mean, stdev, rng) for mean, stdev in zip(means, stdevs)]\n","\n","# Initialize simulation\n","eps = 0.001\n","nsteps = 10000\n","action_values = np.zeros(nactions, dtype=np.float64)\n","action_counts = np.zeros(nactions, dtype=np.int64)\n","\n","# Run simulation\n","for _ in range(nsteps):\n","    if rng.random() < eps:\n","        action = rng.integers(nactions)\n","    else:\n","        action = np.argmax(action_values)\n","    reward = reward_generators[action]()\n","    action_counts[action] += 1\n","    action_values[action] += (reward - action_values[action]) / action_counts[action]\n","print('Training results')\n","for i in range(nactions):\n","  print(f'Action {i}: Count: {action_counts[i]} Value: {action_values[i]}')\n","best_action = np.argmax(action_values)\n","best_value = action_values[best_action]\n","print(f'Best action: {best_action} Value: {best_value}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rn5lf-ILurMs"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}